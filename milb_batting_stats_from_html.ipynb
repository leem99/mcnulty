{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract stats from milb player pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions For Getting Data From Header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_height(h_str):\n",
    "    temp_height = list(map(float,(h_str.split('-'))))\n",
    "    height = temp_height[0]*12 + temp_height[1]\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_position_info(summary_dict):\n",
    "    position_tags = ['first','second','third','shortstop','catcher','outfielder']\n",
    "    positions =  summary_dict['positions'].lower()\n",
    "\n",
    "    for t in position_tags:\n",
    "        if t in positions:\n",
    "            summary_dict[t] = 1\n",
    "        else:\n",
    "            summary_dict[t] = 0\n",
    "\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_mlb_war(summary_dict,player_summary_soup):\n",
    "    # Determine if the player made the majors\n",
    "    debuts_check = player_summary_soup.find_all('a',href=re.compile(\"debuts\"))\n",
    "    if debuts_check:\n",
    "        debut_date = float(debuts_check[0]['href'].split('/')[-1][0:4])\n",
    "        debut = 1\n",
    "\n",
    "        # BBREF Key can be found in this section\n",
    "        debut_link = debuts_check[0].find_next('a')['href']\n",
    "        mlb_id = (re.search(r\"id=(.*)&\", debut_link)).group(1)\n",
    "\n",
    "        # Find Career War\n",
    "        career_table = player_summary_soup.find('div',class_='p1')\n",
    "        try: \n",
    "            float(career_table.find('p').next_sibling.next_sibling.string)\n",
    "        except AttributeError:\n",
    "            war = float(career_table.find('p').string)\n",
    "        else:\n",
    "            war = float(career_table.find('p').next_sibling.next_sibling.string)\n",
    "    else:\n",
    "        debut = 0\n",
    "        mlb_id = 'none'\n",
    "        war = np.nan\n",
    "\n",
    "\n",
    "    summary_dict['war'] = war\n",
    "    summary_dict['mlb'] = debut\n",
    "    summary_dict['mlb_id'] = mlb_id\n",
    "    summary_dict['milb_id'] = html_files[ix].replace('.html','')\n",
    "    \n",
    "    return summary_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_summary_dict(player_summary_soup):\n",
    "\n",
    "    summary_dict = dict()\n",
    "    # Get whether player made MLB and total WAR\n",
    "    summary_dict = add_mlb_war(summary_dict,player_summary_soup)\n",
    "    \n",
    "    strongs = player_summary_soup.find_all('strong')\n",
    "\n",
    "    for su in strongs:\n",
    "        if 'Position' in su.text:\n",
    "            summary_dict['positions'] = re.sub(\n",
    "                '\\n','',su.next_element.next_element).strip()\n",
    "        if 'Bats' in su.text:\n",
    "            b_string = su.next_element.next_element\n",
    "            if 'Right' in b_string:\n",
    "                summary_dict['bats'] = 'right'\n",
    "            elif 'Left' in b_string:\n",
    "                summary_dict['bats'] = 'left'\n",
    "            elif 'Both'in b_string:\n",
    "                summary_dict['bats'] = 'both'\n",
    "        if 'Throws' in su.text:\n",
    "            t_string = su.next_element.next_element\n",
    "            if 'Right' in t_string:\n",
    "                summary_dict['throws'] = 'right'\n",
    "            else:\n",
    "                summary_dict['throws'] = 'left'\n",
    "        if 'Draft' in su.text:\n",
    "            summary_dict['draft'] = player_summary_soup.find_all(\n",
    "                'a',href=re.compile('draft_round'))[-1].string\n",
    "            summary_dict['draft'] = float(re.sub('[^0-9]','',summary_dict['draft']))\n",
    "\n",
    "    spans = player_summary_soup.find_all('span')\n",
    "\n",
    "    for sp in spans:\n",
    "        # Height\n",
    "        try:\n",
    "            sp.attrs['itemprop']\n",
    "        except:\n",
    "            KeyError\n",
    "        else:\n",
    "            if sp.attrs['itemprop'] == 'height':\n",
    "                summary_dict['height'] = make_height(sp.text)\n",
    "\n",
    "        # Weight\n",
    "        try:\n",
    "            sp.attrs['itemprop'] == 'weight'\n",
    "        except:\n",
    "            KeyError\n",
    "        else:\n",
    "            if sp.attrs['itemprop'] == 'weight':\n",
    "                summary_dict['weight'] = float(re.sub(r'[^0-9]','',sp.text))\n",
    "\n",
    "        # Add not Drafted\n",
    "        try:\n",
    "            summary_dict['draft']\n",
    "        except:\n",
    "            KeyError\n",
    "            summary_dict['draft'] = np.nan\n",
    "\n",
    "    summary_dict = add_position_info(summary_dict)\n",
    "    \n",
    "    return summary_dict        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for making player summary sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_summary_dict_sorted(summary_dict):\n",
    "\n",
    "    queue = ['milb_id','mlb_id','mlb','war','draft','bats','throws','height','weight',\n",
    "             'positions','first','second','third','shortstop','catcher','outfielder']\n",
    "\n",
    "    summary_dict_sorted = OrderedDict()\n",
    "    for k in queue:\n",
    "        summary_dict_sorted[k] = summary_dict[k]\n",
    "\n",
    "    return summary_dict_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batting Table Creation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_standard_batting(batter_page):\n",
    "\n",
    "    batter_standard_data = batter_page.find('table',class_='sortable stats_table')\n",
    "\n",
    "    header_name_list = []\n",
    "    # Populate a list containing column headers\n",
    "    header_html = batter_standard_data.find('tr')\n",
    "    for item in header_html.find_all('th'):\n",
    "        header_name_list.append(item.text.strip())\n",
    "\n",
    "    data_html = batter_standard_data.find_all('tr')\n",
    "    data_list = []\n",
    "    for ix, row in enumerate(data_html):\n",
    "        temp_list = []\n",
    "        \n",
    "        try:\n",
    "            re.search('[a-zA-Z]',row.find('th').string)\n",
    "        except TypeError:\n",
    "            break\n",
    "        else:\n",
    "        \n",
    "            if ix >0:\n",
    "                if re.search('[a-zA-Z]',row.find('th').string):\n",
    "                    break\n",
    "                else:\n",
    "                    #print(row.find('th').text.strip())\n",
    "                    temp_year = row.find('th').text.strip()\n",
    "                    temp_year = re.sub('\\-.*$','',temp_year)\n",
    "                    temp_list.append(temp_year)\n",
    "                    for item in row.find_all('td'):\n",
    "                        temp_list.append(item.text.strip())\n",
    "                    data_list.append(temp_list)\n",
    "\n",
    "    batting_df = pd.DataFrame(data_list,columns=header_name_list)\n",
    "    \n",
    "    return batting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_batter_df(df):\n",
    "    numeric_fields = ['Year', 'Age','AgeDif', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR',\\\n",
    "                      'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', \\\n",
    "                      'TB','GDP', 'HBP', 'SH', 'SF', 'IBB']\n",
    "\n",
    "    text_fields = ['Tm', 'Lg','Lev','Aff']\n",
    "    df_clean = pd.DataFrame()\n",
    "    \n",
    "    for nf in numeric_fields:\n",
    "        df_clean[nf] = pd.to_numeric(df[nf])\n",
    "    \n",
    "    for tf in text_fields:\n",
    "        df_clean[tf] = df[tf]\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through Player Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = 'milb_player_pages/'\n",
    "html_files = os.listdir('milb_player_pages')\n",
    "out_path = 'milb_batter_files/'\n",
    "csv_files = os.listdir('milb_batter_files')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23729"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "player skipped\n",
      "500\n",
      "600\n",
      "700\n",
      "player skipped\n",
      "800\n",
      "player skipped\n",
      "900\n",
      "player skipped\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "player skipped\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "player skipped\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "player skipped\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "player skipped\n",
      "4100\n",
      "4200\n",
      "player skipped\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "player skipped\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "player skipped\n",
      "6100\n",
      "6200\n",
      "player skipped\n",
      "6300\n",
      "player skipped\n",
      "6400\n",
      "player skipped\n",
      "player skipped\n",
      "6500\n",
      "6600\n",
      "player skipped\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "player skipped\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "player skipped\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "player skipped\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "player skipped\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "player skipped\n",
      "9200\n",
      "player skipped\n",
      "9300\n",
      "9400\n",
      "player skipped\n",
      "player skipped\n",
      "9500\n",
      "player skipped\n",
      "9600\n",
      "player skipped\n",
      "player skipped\n",
      "9700\n",
      "player skipped\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "player skipped\n",
      "10800\n",
      "player skipped\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "player skipped\n",
      "11600\n",
      "player skipped\n",
      "11700\n",
      "player skipped\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "player skipped\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "player skipped\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "player skipped\n",
      "13300\n",
      "13400\n",
      "player skipped\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "player skipped\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "player skipped\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "player skipped\n",
      "player skipped\n",
      "15300\n",
      "15400\n",
      "player skipped\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "player skipped\n",
      "16000\n",
      "16100\n",
      "player skipped\n",
      "player skipped\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "player skipped\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "player skipped\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "player skipped\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "player skipped\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "player skipped\n",
      "21400\n",
      "player skipped\n",
      "21500\n",
      "player skipped\n",
      "21600\n",
      "player skipped\n",
      "player skipped\n",
      "21700\n",
      "player skipped\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "player skipped\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "player skipped\n",
      "22800\n",
      "22900\n",
      "player skipped\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n"
     ]
    }
   ],
   "source": [
    "with open('milb_batter_summaries.csv', 'w') as csvfile:  # Just use 'w' mode in 3.x\n",
    "\n",
    "    \n",
    "    fieldnames = ['milb_id','mlb_id','mlb','war','draft','bats','throws','height','weight',\n",
    "             'positions','first','second','third','shortstop','catcher','outfielder']\n",
    "    \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()   \n",
    "\n",
    "    for ix, fi in enumerate(html_files):\n",
    "        \n",
    "        #if  fi[:-5]+'.csv' not in csv_files:\n",
    "\n",
    "        html_f = open(fpath + fi,'r')\n",
    "\n",
    "        page = html_f.read()\n",
    "        batter_page = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "        html_f.close()\n",
    "        # Find Header Data\n",
    "        player_summary_soup = batter_page.find('div', {'id':'info'})\n",
    "\n",
    "        try:\n",
    "            summary_dict = make_summary_dict(player_summary_soup)\n",
    "        except (KeyError, AttributeError):\n",
    "            print(\"player skipped\")\n",
    "        else: \n",
    "            summary_dict = make_summary_dict(player_summary_soup)\n",
    "            if 'Pitcher' not in summary_dict['positions']:\n",
    "\n",
    "                try: \n",
    "                    make_summary_dict_sorted(summary_dict)\n",
    "                except KeyError:\n",
    "                    print('player skipped') \n",
    "                else:\n",
    "\n",
    "                    summary_dict = make_summary_dict_sorted(summary_dict)\n",
    "\n",
    "                    #Season By Season Stats\n",
    "                    batter_df = make_standard_batting(batter_page)\n",
    "\n",
    "                    try:\n",
    "                        clean_batter_df(batter_df)\n",
    "                    except KeyError:\n",
    "                        print(\"player skipped\")\n",
    "                    else:\n",
    "\n",
    "                        batter_df_cleaned = clean_batter_df(batter_df)\n",
    "                        batter_df_cleaned['mlb_id'] = summary_dict['mlb_id']\n",
    "                        batter_df_cleaned['milb_id'] = summary_dict['milb_id']\n",
    "\n",
    "                        # if player made major leagues, use that ID for file name\n",
    "                        if summary_dict['mlb'] == 1:\n",
    "                            batter_df_cleaned.to_csv(\n",
    "                                out_path +summary_dict['mlb_id'] +'.csv',\n",
    "                                index=False)\n",
    "                        else:\n",
    "                            batter_df_cleaned.to_csv(\n",
    "                                out_path +summary_dict['milb_id'] +'.csv',\n",
    "                                index=False)\n",
    "\n",
    "                        # Write to summary file\n",
    "                        writer.writerow(summary_dict)\n",
    "\n",
    "        if ix % 100 == 0:\n",
    "            print(ix)\n",
    "        \n",
    "    csvfile.close()\n",
    "    \n",
    "\n",
    "### Combine all Player Files Into Giant CSV\n",
    "\n",
    "saved_batter_files = os.listdir('milb_batter_files/')\n",
    "\n",
    "all_batters_file = open('milb_all_batter_seasons.csv', mode = 'w+')\n",
    "all_batters_writer = csv.writer(all_batters_file, delimiter=',')\n",
    "\n",
    "for ix, bf in enumerate(saved_batter_files):\n",
    "    if '.csv' in bf:\n",
    "        batter_data = open('milb_batter_files/' + bf,'r')\n",
    "        b_file = csv.reader(batter_data,delimiter=',')\n",
    "        \n",
    "        if ix == 0:\n",
    "            for jx, row in enumerate(b_file):\n",
    "                all_batters_writer.writerow(row)\n",
    "        else:\n",
    "            for jx, row in enumerate(b_file):\n",
    "                if jx > 0:\n",
    "                    all_batters_writer.writerow(row)\n",
    "        batter_data.close()\n",
    "        \n",
    "    if ix % 100 == 0:\n",
    "        print(ix)\n",
    "        \n",
    "all_batters_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('milb_all_batter_seasons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('milb_batter_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
